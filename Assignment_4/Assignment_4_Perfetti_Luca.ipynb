{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file...\n",
      "text length 558240\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ***** first 1000 characters ***** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inferno\\n\\n\\n\\ninferno: canto i\\n\\n\\nnel mezzo del cammin di nostra vita\\n  mi ritrovai per una selva oscura\\n  che' la diritta via era smarrita.\\n\\nahi quanto a dir qual era e` cosa dura\\n  esta selva selvaggia e aspra e forte\\n  che nel pensier rinova la paura!\\n\\ntant'e` amara che poco e` piu` morte;\\n  ma per trattar del ben ch'i' vi trovai,\\n  diro` de l'altre cose ch'i' v'ho scorte.\\n\\nio non so ben ridir com'i' v'intrai,\\n  tant'era pien di sonno a quel punto\\n  che la verace via abbandonai.\\n\\nma poi ch'i' fui al pie` d'un colle giunto,\\n  la` dove terminava quella valle\\n  che m'avea di paura il cor compunto,\\n\\nguardai in alto, e vidi le sue spalle\\n  vestite gia` de' raggi del pianeta\\n  che mena dritto altrui per ogne calle.\\n\\nallor fu la paura un poco queta\\n  che nel lago del cor m'era durata\\n  la notte ch'i' passai con tanta pieta.\\n\\ne come quei che con lena affannata\\n  uscito fuor del pelago a la riva\\n  si volge a l'acqua perigliosa e guata,\\n\\ncosi` l'animo mio, ch'ancor fuggiva,\\n  si volse a retro a r\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Opening file...')\n",
    "path = \"divina_commedia.txt\"\n",
    "with io.open(path, encoding='utf-8') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print(\"text length\", len(text))\n",
    "print()\n",
    "print('\\n\\n\\n\\n\\n', '***** first 1000 characters *****', '\\n\\n\\n\\n\\n')\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vita nova' text length 104284\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ***** first 1000 characters ***** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i\\nin quella parte del libro de la mia memoria, dinanzi a la quale poco si potrebbe leggere, si trova una rubrica la quale dice: incipit vita nova. sotto la quale rubrica io trovo scritte le parole le quali è mio intendimento d’asemplare in questo libello; e se non tutte, almeno la loro sentenzia.\\n\\nii\\n[i] nove fiate già appresso lo mio nascimento era tornato lo cielo de la luce quasi a uno medesimo punto, quanto a la sua propria girazione, quando a li miei occhi apparve prima la gloriosa donna de la mia mente, la quale fu chiamata da molti beatrice, li quali non sapeano che si chiamare. ella era in questa vita già stata tanto, che ne lo suo tempo lo cielo stellato era mosso verso la parte d’oriente de le dodici parti l’una d’un grado, sì che quasi dal principio del suo anno nono apparve a me, ed io la vidi quasi da la fine del mio nono. apparve vestita di nobilissimo colore, umile ed onesto, sanguigno, cinta e ornata a la guisa che a la sua giovanissima etade si convenia. in quello punt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with io.open(\"vita_nova.txt\", encoding='utf-8') as file:\n",
    "    external_text = file.read().lower()\n",
    "\n",
    "print(\"'vita nova' text length\", len(external_text))\n",
    "print()\n",
    "print('\\n\\n\\n\\n\\n', '***** first 1000 characters *****', '\\n\\n\\n\\n\\n')\n",
    "external_text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  54\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '<': 12, '>': 13, '?': 14, '[': 15, ']': 16, '`': 17, 'a': 18, 'b': 19, 'c': 20, 'd': 21, 'e': 22, 'f': 23, 'g': 24, 'h': 25, 'i': 26, 'j': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'x': 39, 'y': 40, 'z': 41, '«': 42, '»': 43, 'à': 44, 'â': 45, 'è': 46, 'é': 47, 'ê': 48, 'ì': 49, 'ò': 50, 'ù': 51, '‘': 52, '’': 53}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: ':', 11: ';', 12: '<', 13: '>', 14: '?', 15: '[', 16: ']', 17: '`', 18: 'a', 19: 'b', 20: 'c', 21: 'd', 22: 'e', 23: 'f', 24: 'g', 25: 'h', 26: 'i', 27: 'j', 28: 'l', 29: 'm', 30: 'n', 31: 'o', 32: 'p', 33: 'q', 34: 'r', 35: 's', 36: 't', 37: 'u', 38: 'v', 39: 'x', 40: 'y', 41: 'z', 42: '«', 43: '»', 44: 'à', 45: 'â', 46: 'è', 47: 'é', 48: 'ê', 49: 'ì', 50: 'ò', 51: 'ù', 52: '‘', 53: '’'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text) | set(external_text)))\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars)) # create first dictionary\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences:  186070\n",
      " mezzo del cammin di nostra vi\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30 # chunk length\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('number of sequences: ', len(sentences))\n",
    "print(sentences[11])\n",
    "print(next_chars[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 148856\n",
      "Validation set: 37214\n"
     ]
    }
   ],
   "source": [
    "# first point of assignment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentences_train, sentences_val, next_chars_train, next_chars_val = train_test_split(\n",
    "    sentences, next_chars, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(sentences_train)}\")\n",
    "print(f\"Validation set: {len(sentences_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences:  34752\n",
      " mia memoria, dinanzi a la qua\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "external_sentences = []\n",
    "external_next_chars = []\n",
    "\n",
    "for i in range(0, len(external_text) - maxlen, step):\n",
    "    external_sentences.append(external_text[i: i + maxlen])\n",
    "    external_next_chars.append(external_text[i + maxlen])\n",
    "\n",
    "print('number of sequences: ', len(external_sentences))\n",
    "print(external_sentences[11])\n",
    "print(external_next_chars[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating input and output..\n"
     ]
    }
   ],
   "source": [
    "# encode in one rapresentation\n",
    "print('generating input and output..')\n",
    "\n",
    "def one_hot_encoding(sentences, next_chars, maxlen, chars, char_indices): \n",
    "    x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Training set\n",
    "x_train, y_train = one_hot_encoding(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "\n",
    "# Validation set\n",
    "x_val, y_val = one_hot_encoding(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "\n",
    "# Test set\n",
    "x_test, y_test = one_hot_encoding(external_sentences, external_next_chars, maxlen, chars, char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lperf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,966</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m93,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │         \u001b[38;5;34m6,966\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,662</span> (393.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,662\u001b[0m (393.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,662</span> (393.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,662\u001b[0m (393.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# second point\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def testAfterEpoch(epoch, _):\n",
    "    print()\n",
    "    print()\n",
    "    print('***** Epoch: %d *****' % (epoch+1))\n",
    "    start_index = random.randint(0, len(text)- maxlen - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index : start_index + maxlen]\n",
    "    generated = generated + sentence\n",
    "\n",
    "    print('***** starting sentence *****') \n",
    "    print(sentence)\n",
    "    print('*****************************')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = np.argmax(preds)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=testAfterEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.1697 - loss: 3.0590\n",
      "\n",
      "***** Epoch: 1 *****\n",
      "***** starting sentence *****\n",
      "a donna, in su l'entrar, con a\n",
      "*****************************\n",
      "a donna, in su l'entrar, con a che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 729ms/step - accuracy: 0.1703 - loss: 3.0551 - val_accuracy: 0.3068 - val_loss: 2.3418\n",
      "Epoch 2/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.3080 - loss: 2.2733\n",
      "\n",
      "***** Epoch: 2 *****\n",
      "***** starting sentence *****\n",
      "rga e piena,\n",
      "  cosi` quel fiat\n",
      "*****************************\n",
      "rga e piena,\n",
      "  cosi` quel fiatte l' la lu l'al su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su` su`\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 760ms/step - accuracy: 0.3083 - loss: 2.2722 - val_accuracy: 0.3477 - val_loss: 2.0947\n",
      "Epoch 3/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.3622 - loss: 2.0257\n",
      "\n",
      "***** Epoch: 3 *****\n",
      "***** starting sentence *****\n",
      " l'alto passo tu mi fidi.\n",
      "\n",
      "tu \n",
      "*****************************\n",
      " l'alto passo tu mi fidi.\n",
      "\n",
      "tu la mia che si su` di sua la sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur sur \n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 886ms/step - accuracy: 0.3623 - loss: 2.0253 - val_accuracy: 0.3900 - val_loss: 1.9320\n",
      "Epoch 4/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.3993 - loss: 1.8961\n",
      "\n",
      "***** Epoch: 4 *****\n",
      "***** starting sentence *****\n",
      "i paradiso,\n",
      "  che giu` per l'a\n",
      "*****************************\n",
      "i paradiso,\n",
      "  che giu` per l'altro al man son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son son \n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 1s/step - accuracy: 0.3993 - loss: 1.8958 - val_accuracy: 0.4100 - val_loss: 1.8390\n",
      "Epoch 5/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.4224 - loss: 1.8077\n",
      "\n",
      "***** Epoch: 5 *****\n",
      "***** starting sentence *****\n",
      "ch'ama, che poscia seconda;\n",
      "\n",
      "e\n",
      "*****************************\n",
      "ch'ama, che poscia seconda;\n",
      "\n",
      "e come con la compi a la come al monte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'altro a la come a la compian conte,\n",
      "  che l'a\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.4224 - loss: 1.8075 - val_accuracy: 0.4283 - val_loss: 1.7916\n",
      "Epoch 6/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.4417 - loss: 1.7452\n",
      "\n",
      "***** Epoch: 6 *****\n",
      "***** starting sentence *****\n",
      "dir si` cosa nuova>>,\n",
      "  rispuo\n",
      "*****************************\n",
      "dir si` cosa nuova>>,\n",
      "  rispuose a la cia` di sia che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si ch\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.4418 - loss: 1.7451 - val_accuracy: 0.4428 - val_loss: 1.7423\n",
      "Epoch 7/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.4582 - loss: 1.6893\n",
      "\n",
      "***** Epoch: 7 *****\n",
      "***** starting sentence *****\n",
      ",\n",
      "  tre volte cinse me, si` co\n",
      "*****************************\n",
      ",\n",
      "  tre volte cinse me, si` come suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo s\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.4582 - loss: 1.6892 - val_accuracy: 0.4511 - val_loss: 1.7119\n",
      "Epoch 8/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4711 - loss: 1.6473\n",
      "\n",
      "***** Epoch: 8 *****\n",
      "***** starting sentence *****\n",
      "io la veggio nel verace spegli\n",
      "*****************************\n",
      "io la veggio nel verace speglia,\n",
      "  che 'l suo si scalla si scalla\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo si scalla si scalla scalta\n",
      "  ch'al suo s\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.4711 - loss: 1.6472 - val_accuracy: 0.4577 - val_loss: 1.6850\n",
      "Epoch 9/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.4812 - loss: 1.6117\n",
      "\n",
      "***** Epoch: 9 *****\n",
      "***** starting sentence *****\n",
      "ole nel beato chiostro\n",
      "  son l\n",
      "*****************************\n",
      "ole nel beato chiostro\n",
      "  son le suo per le suo per le suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che di la cia per la contando in suo prese\n",
      "  che \n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.4812 - loss: 1.6116 - val_accuracy: 0.4655 - val_loss: 1.6578\n",
      "Epoch 10/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.4915 - loss: 1.5782\n",
      "\n",
      "***** Epoch: 10 *****\n",
      "***** starting sentence *****\n",
      "l qual non e` a che s'aspiri,\n",
      "\n",
      "*****************************\n",
      "l qual non e` a che s'aspiri,\n",
      "  e come si facea che si facea si faccia.\n",
      "\n",
      "e io altra che si facea che si faccia.\n",
      "\n",
      "e io a le suo prima si facea contenti\n",
      "  che l'altra si facea che si faccia.\n",
      "\n",
      "e io a le suo prima si facea contenti\n",
      "  che l'altra si facea che si faccia.\n",
      "\n",
      "e io a le suo prima si facea contenti\n",
      "  che l'altra si facea che si faccia.\n",
      "\n",
      "e io a le suo prima si facea contenti\n",
      "  che l'altra si facea che si faccia.\n",
      "\n",
      "e io a le\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.4915 - loss: 1.5782 - val_accuracy: 0.4769 - val_loss: 1.6306\n",
      "Epoch 11/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.5008 - loss: 1.5438\n",
      "\n",
      "***** Epoch: 11 *****\n",
      "***** starting sentence *****\n",
      "i tacer nol posso; e per le no\n",
      "*****************************\n",
      "i tacer nol posso; e per le non si fara\n",
      "  di morte a l'altro son piu` convien di forme al posso sormo,\n",
      "  che' l'altro son piu` come a la sua farma porta\n",
      "  che si fara e altro son piu` si convien di forme al posso sormo,\n",
      "  che' l'altro son piu` come a la sua farma porta\n",
      "  che si fara e altro son piu` si convien di forme al posso sormo,\n",
      "  che' l'altro son piu` come a la sua farma porta\n",
      "  che si fara e altro son piu` si convien d\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 993ms/step - accuracy: 0.5008 - loss: 1.5439 - val_accuracy: 0.4761 - val_loss: 1.6275\n",
      "Epoch 12/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5087 - loss: 1.5167\n",
      "\n",
      "***** Epoch: 12 *****\n",
      "***** starting sentence *****\n",
      "e mi lodero` sovente a lui\".\n",
      " \n",
      "*****************************\n",
      "e mi lodero` sovente a lui\".\n",
      "  e come son per lo sperso di coloro\n",
      "  che son per lo sperso di colui che s'accosse\n",
      "  di piu` si morte a la prima assente\n",
      "  che son piu` al mondo di colui che s'accosse\n",
      "  di piu` si morte a la prima assente\n",
      "  che son piu` al mondo di colui che s'accosse\n",
      "  di piu` si morte a la prima assente\n",
      "  che son piu` al mondo di colui che s'accosse\n",
      "  di piu` si morte a la prima assente\n",
      "  che son piu` al mondo \n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 798ms/step - accuracy: 0.5087 - loss: 1.5167 - val_accuracy: 0.4815 - val_loss: 1.6170\n",
      "Epoch 13/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.5190 - loss: 1.4890\n",
      "\n",
      "***** Epoch: 13 *****\n",
      "***** starting sentence *****\n",
      "zza piu` fanno piu` suso,\n",
      "  e \n",
      "*****************************\n",
      "zza piu` fanno piu` suso,\n",
      "  e quel che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 844ms/step - accuracy: 0.5189 - loss: 1.4891 - val_accuracy: 0.4898 - val_loss: 1.6000\n",
      "Epoch 14/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.5233 - loss: 1.4690\n",
      "\n",
      "***** Epoch: 14 *****\n",
      "***** starting sentence *****\n",
      "i l'assenso diede,\n",
      "  vide nel \n",
      "*****************************\n",
      "i l'assenso diede,\n",
      "  vide nel son che son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son piu` che s'accorse\n",
      "  che l'altra spera son p\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 795ms/step - accuracy: 0.5233 - loss: 1.4691 - val_accuracy: 0.4941 - val_loss: 1.5908\n",
      "Epoch 15/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.5312 - loss: 1.4473\n",
      "\n",
      "***** Epoch: 15 *****\n",
      "***** starting sentence *****\n",
      "i ghin di tacco ebbe la morte,\n",
      "*****************************\n",
      "i ghin di tacco ebbe la morte,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  che la sua presso a le prese in suo veno,\n",
      "  c\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 736ms/step - accuracy: 0.5312 - loss: 1.4474 - val_accuracy: 0.4905 - val_loss: 1.6050\n",
      "Epoch 16/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.5362 - loss: 1.4282\n",
      "\n",
      "***** Epoch: 16 *****\n",
      "***** starting sentence *****\n",
      "etta questa faccia,\n",
      "\n",
      "l'ossa de\n",
      "*****************************\n",
      "etta questa faccia,\n",
      "\n",
      "l'ossa del ciel che tu vede il sole al pastor di lor discerno a la pressa\n",
      "  di pietro a le la piace a le stalletto\n",
      "  di quella che tu per l'altra far le stritto scorte\n",
      "  di pie` d'un per l'altra spera\n",
      "  di quella che tu per l'altra far le stritto scorte\n",
      "  di pie` d'un per l'altra spera\n",
      "  di quella che tu per l'altra far le stritto scorte\n",
      "  di pie` d'un per l'altra spera\n",
      "  di quella che tu per l'altra far l\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 731ms/step - accuracy: 0.5362 - loss: 1.4283 - val_accuracy: 0.4879 - val_loss: 1.5975\n",
      "Epoch 17/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.5404 - loss: 1.4145\n",
      "\n",
      "***** Epoch: 17 *****\n",
      "***** starting sentence *****\n",
      "io\";\n",
      "\n",
      "ma non fia da casal ne' \n",
      "*****************************\n",
      "io\";\n",
      "\n",
      "ma non fia da casal ne' che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si che si c\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.5404 - loss: 1.4146 - val_accuracy: 0.4955 - val_loss: 1.5958\n",
      "Epoch 18/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.5472 - loss: 1.3906\n",
      "\n",
      "***** Epoch: 18 *****\n",
      "***** starting sentence *****\n",
      "ra lor tolto.\n",
      "\n",
      "forse per forza\n",
      "*****************************\n",
      "ra lor tolto.\n",
      "\n",
      "forse per forza si` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la` di sua vita\n",
      "  la sua vita di la`\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 968ms/step - accuracy: 0.5472 - loss: 1.3908 - val_accuracy: 0.4962 - val_loss: 1.5965\n",
      "Epoch 19/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.5569 - loss: 1.3643\n",
      "\n",
      "***** Epoch: 19 *****\n",
      "***** starting sentence *****\n",
      "telletto.\n",
      "\n",
      "quinci si puo` vede\n",
      "*****************************\n",
      "telletto.\n",
      "\n",
      "quinci si puo` veder l'altro passo,\n",
      "  e poi che l'altro di colui che piu` non pare\n",
      "  che l'altro di colui che per lo spersi\n",
      "  di sua vita di la` da la virta\n",
      "  di la` da la mente che piu` non si torte\n",
      "  l'un di la` da la mente che piu` prima\n",
      "  di la` da la mente che piu` non si torte\n",
      "  l'un di la` da la mente che piu` prima\n",
      "  di la` da la mente che piu` non si torte\n",
      "  l'un di la` da la mente che piu` prima\n",
      "  di la` d\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 940ms/step - accuracy: 0.5568 - loss: 1.3645 - val_accuracy: 0.4940 - val_loss: 1.5968\n",
      "Epoch 20/20\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.5506 - loss: 1.4500\n",
      "\n",
      "***** Epoch: 20 *****\n",
      "***** starting sentence *****\n",
      "voglio che t'ammanti.\n",
      "\n",
      "sempre \n",
      "*****************************\n",
      "voglio che t'ammanti.\n",
      "\n",
      "sempre a la carca in contra in giusto in su la reda,\n",
      "  e se di non par la sua cade a me son pianto\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente che son piu` a la sua face\n",
      "  che la mente\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 941ms/step - accuracy: 0.5506 - loss: 1.4495 - val_accuracy: 0.4929 - val_loss: 1.6021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b4d2be2900>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size = 2048, \n",
    "          epochs = 20, \n",
    "          callbacks = [print_callback],\n",
    "          validation_data =(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
