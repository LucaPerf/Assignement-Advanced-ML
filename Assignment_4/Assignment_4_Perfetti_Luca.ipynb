{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset \n",
    "\n",
    "The dataset 'divina_commedia.txt' is imported, containing the text of Dante's Divine Comedy. The file includes additional lines that are not part of the original text but provide information about the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file...\n",
      "text length 558240\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ***** first 1000 characters ***** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inferno\\n\\n\\n\\ninferno: canto i\\n\\n\\nnel mezzo del cammin di nostra vita\\n  mi ritrovai per una selva oscura\\n  che' la diritta via era smarrita.\\n\\nahi quanto a dir qual era e` cosa dura\\n  esta selva selvaggia e aspra e forte\\n  che nel pensier rinova la paura!\\n\\ntant'e` amara che poco e` piu` morte;\\n  ma per trattar del ben ch'i' vi trovai,\\n  diro` de l'altre cose ch'i' v'ho scorte.\\n\\nio non so ben ridir com'i' v'intrai,\\n  tant'era pien di sonno a quel punto\\n  che la verace via abbandonai.\\n\\nma poi ch'i' fui al pie` d'un colle giunto,\\n  la` dove terminava quella valle\\n  che m'avea di paura il cor compunto,\\n\\nguardai in alto, e vidi le sue spalle\\n  vestite gia` de' raggi del pianeta\\n  che mena dritto altrui per ogne calle.\\n\\nallor fu la paura un poco queta\\n  che nel lago del cor m'era durata\\n  la notte ch'i' passai con tanta pieta.\\n\\ne come quei che con lena affannata\\n  uscito fuor del pelago a la riva\\n  si volge a l'acqua perigliosa e guata,\\n\\ncosi` l'animo mio, ch'ancor fuggiva,\\n  si volse a retro a r\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Opening file...')\n",
    "path = \"divina_commedia.txt\"\n",
    "with io.open(path, encoding='utf-8') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print(\"text length\", len(text))\n",
    "print()\n",
    "print('\\n\\n\\n\\n\\n', '***** first 1000 characters *****', '\\n\\n\\n\\n\\n')\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length 558176\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ***** first 1000 characters ***** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"inferno\\n\\n\\n\\ninferno: canto i\\n\\n\\nnel mezzo del cammin di nostra vita\\n  mi ritrovai per una selva oscura\\n  che' la diritta via era smarrita.\\n\\nahi quanto a dir qual era e` cosa dura\\n  esta selva selvaggia e aspra e forte\\n  che nel pensier rinova la paura!\\n\\ntant'e` amara che poco e` piu` morte;\\n  ma per trattar del ben ch'i' vi trovai,\\n  diro` de l'altre cose ch'i' v'ho scorte.\\n\\nio non so ben ridir com'i' v'intrai,\\n  tant'era pien di sonno a quel punto\\n  che la verace via abbandonai.\\n\\nma poi ch'i' fui al pie` d'un colle giunto,\\n  la` dove terminava quella valle\\n  che m'avea di paura il cor compunto,\\n\\nguardai in alto, e vidi le sue spalle\\n  vestite gia` de' raggi del pianeta\\n  che mena dritto altrui per ogne calle.\\n\\nallor fu la paura un poco queta\\n  che nel lago del cor m'era durata\\n  la notte ch'i' passai con tanta pieta.\\n\\ne come quei che con lena affannata\\n  uscito fuor del pelago a la riva\\n  si volge a l'acqua perigliosa e guata,\\n\\ncosi` l'animo mio, ch'ancor fuggiva,\\n  si volse a retro a r\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove information about the author\n",
    "text = re.sub(r\"(e-text courtesy progetto manuzio)\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "print(\"text length\", len(text))\n",
    "print()\n",
    "print('\\n\\n\\n\\n\\n', '***** first 1000 characters *****', '\\n\\n\\n\\n\\n')\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "During the data preprocessing phase, the text is divided into individual *canti*, removing unnecessary titles to retain only the 100 *canti* from the Divine Comedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of canti:  100\n",
      "lo giorno se n'andava, e l'aere bruno\n",
      "  toglieva li animai che sono in terra\n",
      "  da le fatiche loro; e io sol uno\n",
      "\n",
      "m'apparecchiava a sostener la guerra\n",
      "  si` del cammino e si` de la pietate,\n",
      "  che ritrarra` la mente che non erra.\n",
      "\n",
      "o muse, o alto ingegno, or m'aiutate;\n",
      "  o mente che scrivesti cio` ch'io vidi,\n",
      "  qui si parra` la tua nobilitate.\n",
      "\n",
      "io cominciai: <<poeta che mi guidi,\n",
      "  guarda la mia virtu` s'ell'e` possente,\n",
      "  prima ch'a l'alto passo tu mi fidi.\n",
      "\n",
      "tu dici che di silvio il parente,\n",
      "  corruttibile ancora, ad immortale\n",
      "  secolo ando`, e fu sensibilmente.\n",
      "\n",
      "pero`, se l'avversario d'ogne male\n",
      "  cortese i fu, pensando l'alto effetto\n",
      "  ch'uscir dovea di lui e 'l chi e 'l quale,\n",
      "\n",
      "non pare indegno ad omo d'intelletto;\n",
      "  ch'e' fu de l'alma roma e di suo impero\n",
      "  ne l'empireo ciel per padre eletto:\n",
      "\n",
      "la quale e 'l quale, a voler dir lo vero,\n",
      "  fu stabilita per lo loco santo\n",
      "  u' siede il successor del maggior piero.\n",
      "\n",
      "per quest'andata onde li dai tu vanto,\n",
      "  intese cose che furon cagione\n",
      "  di sua vittoria e del papale ammanto.\n",
      "\n",
      "andovvi poi lo vas d'elezione,\n",
      "  per recarne conforto a quella fede\n",
      "  ch'e` principio a la via di salvazione.\n",
      "\n",
      "ma io perche' venirvi? o chi 'l concede?\n",
      "  io non enea, io non paulo sono:\n",
      "  me degno a cio` ne' io ne' altri 'l crede.\n",
      "\n",
      "per che, se del venire io m'abbandono,\n",
      "  temo che la venuta non sia folle.\n",
      "  se' savio; intendi me' ch'i' non ragiono>>.\n",
      "\n",
      "e qual e` quei che disvuol cio` che volle\n",
      "  e per novi pensier cangia proposta,\n",
      "  si` che dal cominciar tutto si tolle,\n",
      "\n",
      "tal mi fec'io 'n quella oscura costa,\n",
      "  perche', pensando, consumai la 'mpresa\n",
      "  che fu nel cominciar cotanto tosta.\n",
      "\n",
      "<<s'i' ho ben la parola tua intesa>>,\n",
      "  rispuose del magnanimo quell'ombra;\n",
      "  <<l'anima tua e` da viltade offesa;\n",
      "\n",
      "la qual molte fiate l'omo ingombra\n",
      "  si` che d'onrata impresa lo rivolve,\n",
      "  come falso veder bestia quand'ombra.\n",
      "\n",
      "da questa tema accio` che tu ti solve,\n",
      "  dirotti perch'io venni e quel ch'io 'ntesi\n",
      "  nel primo punto che di te mi dolve.\n",
      "\n",
      "io era tra color che son sospesi,\n",
      "  e donna mi chiamo` beata e bella,\n",
      "  tal che di comandare io la richiesi.\n",
      "\n",
      "lucevan li occhi suoi piu` che la stella;\n",
      "  e cominciommi a dir soave e piana,\n",
      "  con angelica voce, in sua favella:\n",
      "\n",
      "\"o anima cortese mantoana,\n",
      "  di cui la fama ancor nel mondo dura,\n",
      "  e durera` quanto 'l mondo lontana,\n",
      "\n",
      "l'amico mio, e non de la ventura,\n",
      "  ne la diserta piaggia e` impedito\n",
      "  si` nel cammin, che volt'e` per paura;\n",
      "\n",
      "e temo che non sia gia` si` smarrito,\n",
      "  ch'io mi sia tardi al soccorso levata,\n",
      "  per quel ch'i' ho di lui nel cielo udito.\n",
      "\n",
      "or movi, e con la tua parola ornata\n",
      "  e con cio` c'ha mestieri al suo campare\n",
      "  l'aiuta, si` ch'i' ne sia consolata.\n",
      "\n",
      "i' son beatrice che ti faccio andare;\n",
      "  vegno del loco ove tornar disio;\n",
      "  amor mi mosse, che mi fa parlare.\n",
      "\n",
      "quando saro` dinanzi al segnor mio,\n",
      "  di te mi lodero` sovente a lui\".\n",
      "  tacette allora, e poi comincia' io:\n",
      "\n",
      "\"o donna di virtu`, sola per cui\n",
      "  l'umana spezie eccede ogne contento\n",
      "  di quel ciel c'ha minor li cerchi sui,\n",
      "\n",
      "tanto m'aggrada il tuo comandamento,\n",
      "  che l'ubidir, se gia` fosse, m'e` tardi;\n",
      "  piu` non t'e` uo' ch'aprirmi il tuo talento.\n",
      "\n",
      "ma dimmi la cagion che non ti guardi\n",
      "  de lo scender qua giuso in questo centro\n",
      "  de l'ampio loco ove tornar tu ardi\".\n",
      "\n",
      "\"da che tu vuo' saver cotanto a dentro,\n",
      "  dirotti brievemente\", mi rispuose,\n",
      "  \"perch'io non temo di venir qua entro.\n",
      "\n",
      "temer si dee di sole quelle cose\n",
      "  c'hanno potenza di fare altrui male;\n",
      "  de l'altre no, che' non son paurose.\n",
      "\n",
      "i' son fatta da dio, sua merce', tale,\n",
      "  che la vostra miseria non mi tange,\n",
      "  ne' fiamma d'esto incendio non m'assale.\n",
      "\n",
      "donna e` gentil nel ciel che si compiange\n",
      "  di questo 'mpedimento ov'io ti mando,\n",
      "  si` che duro giudicio la` su` frange.\n",
      "\n",
      "questa chiese lucia in suo dimando\n",
      "  e disse: - or ha bisogno il tuo fedele\n",
      "  di te, e io a te lo raccomando -.\n",
      "\n",
      "lucia, nimica di ciascun crudele,\n",
      "  si mosse, e venne al loco dov'i' era,\n",
      "  che mi sedea con l'antica rachele.\n",
      "\n",
      "disse: - beatrice, loda di dio vera,\n",
      "  che' non soccorri quei che t'amo` tanto,\n",
      "  ch'usci` per te de la volgare schiera?\n",
      "\n",
      "non odi tu la pieta del suo pianto?\n",
      "  non vedi tu la morte che 'l combatte\n",
      "  su la fiumana ove 'l mar non ha vanto? -.\n",
      "\n",
      "al mondo non fur mai persone ratte\n",
      "  a far lor pro o a fuggir lor danno,\n",
      "  com'io, dopo cotai parole fatte,\n",
      "\n",
      "venni qua giu` del mio beato scanno,\n",
      "  fidandomi del tuo parlare onesto,\n",
      "  ch'onora te e quei ch'udito l'hanno\".\n",
      "\n",
      "poscia che m'ebbe ragionato questo,\n",
      "  li occhi lucenti lagrimando volse;\n",
      "  per che mi fece del venir piu` presto;\n",
      "\n",
      "e venni a te cosi` com'ella volse;\n",
      "  d'inanzi a quella fiera ti levai\n",
      "  che del bel monte il corto andar ti tolse.\n",
      "\n",
      "dunque: che e`? perche', perche' restai?\n",
      "  perche' tanta vilta` nel core allette?\n",
      "  perche' ardire e franchezza non hai,\n",
      "\n",
      "poscia che tai tre donne benedette\n",
      "  curan di te ne la corte del cielo,\n",
      "  e 'l mio parlar tanto ben ti promette?>>.\n",
      "\n",
      "quali fioretti dal notturno gelo\n",
      "  chinati e chiusi, poi che 'l sol li 'mbianca\n",
      "  si drizzan tutti aperti in loro stelo,\n",
      "\n",
      "tal mi fec'io di mia virtude stanca,\n",
      "  e tanto buono ardire al cor mi corse,\n",
      "  ch'i' cominciai come persona franca:\n",
      "\n",
      "<<oh pietosa colei che mi soccorse!\n",
      "  e te cortese ch'ubidisti tosto\n",
      "  a le vere parole che ti porse!\n",
      "\n",
      "tu m'hai con disiderio il cor disposto\n",
      "  si` al venir con le parole tue,\n",
      "  ch'i' son tornato nel primo proposto.\n",
      "\n",
      "or va, ch'un sol volere e` d'ambedue:\n",
      "  tu duca, tu segnore, e tu maestro>>.\n",
      "  cosi` li dissi; e poi che mosso fue,\n",
      "\n",
      "intrai per lo cammino alto e silvestro.\n"
     ]
    }
   ],
   "source": [
    "canti = re.split(r'(?<=\\n)(inferno|purgatorio|paradiso):\\s*canto\\s*[ivxlcdm]+\\n*', text)\n",
    "\n",
    "canti = [canto.strip() for canto in canti if canto.strip() and canto.lower() not in ['inferno', 'purgatorio', 'paradiso']]\n",
    "\n",
    "# The first element of 'cantos', namely 'Inferno', is removed from the list to obtain a list containing only the cantos. \n",
    "if canti[0].lower() in ['inferno', 'purgatorio', 'paradiso']:\n",
    "    canti = canti[1:]\n",
    "\n",
    "print(\"Number of canti: \", len(canti))\n",
    "\n",
    "# Print second canto\n",
    "print(canti[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  40\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '<': 12, '>': 13, '?': 14, '`': 15, 'a': 16, 'b': 17, 'c': 18, 'd': 19, 'e': 20, 'f': 21, 'g': 22, 'h': 23, 'i': 24, 'j': 25, 'l': 26, 'm': 27, 'n': 28, 'o': 29, 'p': 30, 'q': 31, 'r': 32, 's': 33, 't': 34, 'u': 35, 'v': 36, 'x': 37, 'y': 38, 'z': 39}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: ':', 11: ';', 12: '<', 13: '>', 14: '?', 15: '`', 16: 'a', 17: 'b', 18: 'c', 19: 'd', 20: 'e', 21: 'f', 22: 'g', 23: 'h', 24: 'i', 25: 'j', 26: 'l', 27: 'm', 28: 'n', 29: 'o', 30: 'p', 31: 'q', 32: 'r', 33: 's', 34: 't', 35: 'u', 36: 'v', 37: 'x', 38: 'y', 39: 'z'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generete_sequences(text, maxlen, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    \n",
    "    return sentences, next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(sentences, next_chars, maxlen, chars, char_indices):\n",
    "    x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance(history):\n",
    "    flg, ax = plt.subplots(1,2)\n",
    "    flg.tight_layout()\n",
    "    train_acc = history.history['accuracy']\n",
    "    train_loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].plot(train_loss, label='Training Loss')\n",
    "    ax[0].plot(val_loss, label='Validation Loss')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_title('Accuracy')\n",
    "    ax[1].plot(train_acc, label='Training Accuracy')\n",
    "    ax[1].plot(val_acc, label='Validation Accuracy')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def testAfterEpoch(epoch, _, maxlen, text, model):\n",
    "    print()\n",
    "    print()\n",
    "    print('***** Epoch: %d *****' % (epoch+1))\n",
    "    start_index = random.randint(0, len(text)- maxlen - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index : start_index + maxlen]\n",
    "    generated = generated + sentence\n",
    "\n",
    "    print('***** starting sentence *****') \n",
    "    print(sentence)\n",
    "    print('*****************************')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = np.argmax(preds)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide the sequence into training, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Divide the sequence into training, validation and testing in an unbalanced way.\n",
    "\n",
    "Si divide il dataset in training, validation e test andando a prendere in modo randomico i canti appena divisi. Al training si assegna il 70 percento dei canti, al validation il 20 e 10 per il test. \n",
    "\n",
    "Dato che i canti vengono mescolati all'inizo, questo potrebbe influire sui risultati per questo è stato definito che è un modo non bilanciato. \n",
    "\n",
    "Per questo primo addestramento è stata mantenuta l'architettura usata durante il laboratorio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 70 canti\n",
      "Validation set: 20 canti\n",
      "Test set: 10 canti\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(canti)\n",
    "\n",
    "train_size = int(0.7 * len(canti))\n",
    "val_size = int(0.2 * len(canti))\n",
    "test_size = len(canti) - train_size - val_size\n",
    "\n",
    "train_canti = canti[:train_size]\n",
    "val_canti = canti[train_size:train_size + val_size]\n",
    "test_canti = canti[train_size + val_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_canti)} canti\")\n",
    "print(f\"Validation set: {len(val_canti)} canti\")\n",
    "print(f\"Test set: {len(test_canti)} canti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences:  128555\n",
      "\n",
      "  giu` nel secondo, che men l\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30 # chunk length\n",
    "step = 3\n",
    "\n",
    "sentences_train, next_chars_train = generete_sequences(''.join(train_canti), maxlen, step)\n",
    "sentences_val, next_chars_val = generete_sequences(''.join(val_canti), maxlen, step)\n",
    "sentences_test, next_chars_test = generete_sequences(''.join(test_canti), maxlen, step)\n",
    "\n",
    "print('number of sequences: ', len(sentences_train))\n",
    "print(sentences_train[11])\n",
    "print(next_chars_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_sequences(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "x_val, y_val = encode_sequences(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "x_test, y_test = encode_sequences(sentences_test, next_chars_test, maxlen, chars, char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (128555, 30, 40)\n",
      "y_train shape: (128555, 40)\n",
      "x_val shape: (37821, 30, 40)\n",
      "y_val shape: (37821, 40)\n",
      "x_test shape: (18765, 30, 40)\n",
      "y_test shape: (18765, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungiamo all'architettura di rete anche la metrica di accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,160</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m86,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m5,160\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,688</span> (358.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,688\u001b[0m (358.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,688</span> (358.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,688\u001b[0m (358.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_canti = ''.join(train_canti)\n",
    "\n",
    "print_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: testAfterEpoch(\n",
    "        epoch,\n",
    "        logs,\n",
    "        maxlen,\n",
    "        text_canti,\n",
    "        model\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.1708 - loss: 3.0630\n",
      "\n",
      "***** Epoch: 1 *****\n",
      "***** starting sentence *****\n",
      "i si dice,\n",
      "  di qua che dire e\n",
      "*****************************\n",
      "i si dice,\n",
      "  di qua che dire e di si si se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se se \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 858ms/step - accuracy: 0.1715 - loss: 3.0585 - val_accuracy: 0.2936 - val_loss: 2.3692\n",
      "Epoch 2/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.3088 - loss: 2.2679\n",
      "\n",
      "***** Epoch: 2 *****\n",
      "***** starting sentence *****\n",
      "erso questa rivera,\n",
      "  tanto ch\n",
      "*****************************\n",
      "erso questa rivera,\n",
      "  tanto che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'alla che l'\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 861ms/step - accuracy: 0.3091 - loss: 2.2667 - val_accuracy: 0.3342 - val_loss: 2.1236\n",
      "Epoch 3/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.3631 - loss: 2.0264\n",
      "\n",
      "***** Epoch: 3 *****\n",
      "***** starting sentence *****\n",
      "e io <<alcun compenso>>,\n",
      "  dis\n",
      "*****************************\n",
      "e io <<alcun compenso>>,\n",
      "  discia che l' con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con la con \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 912ms/step - accuracy: 0.3632 - loss: 2.0259 - val_accuracy: 0.3837 - val_loss: 1.9395\n",
      "Epoch 4/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.3913 - loss: 1.9067\n",
      "\n",
      "***** Epoch: 4 *****\n",
      "***** starting sentence *****\n",
      " meta.\n",
      "\n",
      "vedrassi la lussuria e\n",
      "*****************************\n",
      " meta.\n",
      "\n",
      "vedrassi la lussuria e se la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la manta,\n",
      "  che 'l per la mente si per la man\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 884ms/step - accuracy: 0.3915 - loss: 1.9062 - val_accuracy: 0.4150 - val_loss: 1.8331\n",
      "Epoch 5/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4234 - loss: 1.8023\n",
      "\n",
      "***** Epoch: 5 *****\n",
      "***** starting sentence *****\n",
      ">.\n",
      "\n",
      "noi aggirammo a tondo quel\n",
      "*****************************\n",
      ">.\n",
      "\n",
      "noi aggirammo a tondo quel che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di se la si` che si volte\n",
      "  che si verti di\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 771ms/step - accuracy: 0.4235 - loss: 1.8022 - val_accuracy: 0.4288 - val_loss: 1.7913\n",
      "Epoch 6/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.4404 - loss: 1.7479\n",
      "\n",
      "***** Epoch: 6 *****\n",
      "***** starting sentence *****\n",
      "giando la moneta,\n",
      "  quel che m\n",
      "*****************************\n",
      "giando la moneta,\n",
      "  quel che mi per la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la se' la se' per la se' la se' la \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 799ms/step - accuracy: 0.4405 - loss: 1.7477 - val_accuracy: 0.4479 - val_loss: 1.7421\n",
      "Epoch 7/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.4587 - loss: 1.6905\n",
      "\n",
      "***** Epoch: 7 *****\n",
      "***** starting sentence *****\n",
      "erche' lei che di` e notte fil\n",
      "*****************************\n",
      "erche' lei che di` e notte filla,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si perse si perso,\n",
      "  che piu` che si pers\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 788ms/step - accuracy: 0.4588 - loss: 1.6904 - val_accuracy: 0.4512 - val_loss: 1.7083\n",
      "Epoch 8/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.4702 - loss: 1.6450\n",
      "\n",
      "***** Epoch: 8 *****\n",
      "***** starting sentence *****\n",
      "!>>, diss'io lui, <<per entro \n",
      "*****************************\n",
      "!>>, diss'io lui, <<per entro a la suo preno\n",
      "  che tu con la che tu con la che son la contesto raggior di sole\n",
      "  che tu con la che tu con la che son la contesto raggior di sole\n",
      "  che tu con la che tu con la che son la contesto raggior di sole\n",
      "  che tu con la che tu con la che son la contesto raggior di sole\n",
      "  che tu con la che tu con la che son la contesto raggior di sole\n",
      "  che tu con la che tu con la che son la contesto raggi\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 813ms/step - accuracy: 0.4702 - loss: 1.6450 - val_accuracy: 0.4634 - val_loss: 1.6778\n",
      "Epoch 9/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.4837 - loss: 1.6084\n",
      "\n",
      "***** Epoch: 9 *****\n",
      "***** starting sentence *****\n",
      "e da lui contenute.\n",
      "\n",
      "li altri \n",
      "*****************************\n",
      "e da lui contenute.\n",
      "\n",
      "li altri per la vira e la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      "  che la vica non si piu` che tutto a la vica,\n",
      " \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 753ms/step - accuracy: 0.4837 - loss: 1.6084 - val_accuracy: 0.4646 - val_loss: 1.6819\n",
      "Epoch 10/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.4933 - loss: 1.5745\n",
      "\n",
      "***** Epoch: 10 *****\n",
      "***** starting sentence *****\n",
      "u maggio\n",
      "  che 'l parlar mostr\n",
      "*****************************\n",
      "u maggio\n",
      "  che 'l parlar mostro a la suo ratto sole\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scala\n",
      "  che l'altro a la volta che la scal\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 799ms/step - accuracy: 0.4933 - loss: 1.5746 - val_accuracy: 0.4738 - val_loss: 1.6396\n",
      "Epoch 11/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.5072 - loss: 1.5308\n",
      "\n",
      "***** Epoch: 11 *****\n",
      "***** starting sentence *****\n",
      " pie` si rattrappa.era gia` l'\n",
      "*****************************\n",
      " pie` si rattrappa.era gia` l'altro scoppo,\n",
      "\n",
      "e quel che tu ti tempi che tu si prima\n",
      "  che tu ti tempi che tu ti tempia,\n",
      "  che tu ti ti fista in tu te partira\n",
      "  che tu ti tempi che tu ti tempia,\n",
      "  che tu ti ti fista in tu te partira\n",
      "  che tu ti tempi che tu ti tempia,\n",
      "  che tu ti ti fista in tu te partira\n",
      "  che tu ti tempi che tu ti tempia,\n",
      "  che tu ti ti fista in tu te partira\n",
      "  che tu ti tempi che tu ti tempia,\n",
      "  che tu ti ti\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 775ms/step - accuracy: 0.5071 - loss: 1.5310 - val_accuracy: 0.4808 - val_loss: 1.6260\n",
      "Epoch 12/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.5129 - loss: 1.5119\n",
      "\n",
      "***** Epoch: 12 *****\n",
      "***** starting sentence *****\n",
      "che tu sempiterni\n",
      "  desiderato\n",
      "*****************************\n",
      "che tu sempiterni\n",
      "  desiderato di sole e con la sua corta\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la sua contan di suo come son la sua contanda\n",
      "  che la\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 755ms/step - accuracy: 0.5129 - loss: 1.5120 - val_accuracy: 0.4860 - val_loss: 1.6244\n",
      "Epoch 13/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.5211 - loss: 1.4815\n",
      "\n",
      "***** Epoch: 13 *****\n",
      "***** starting sentence *****\n",
      " vidi un che mirava\n",
      "  pur me, \n",
      "*****************************\n",
      " vidi un che mirava\n",
      "  pur me, per la sua che si consesse.\n",
      "\n",
      "lo suo piu` che 'l mio disse: <<quando l'altro fisto si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si piena\n",
      "  di quel che si contende che si pie\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 757ms/step - accuracy: 0.5210 - loss: 1.4816 - val_accuracy: 0.4826 - val_loss: 1.6215\n",
      "Epoch 14/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.5264 - loss: 1.4608\n",
      "\n",
      "***** Epoch: 14 *****\n",
      "***** starting sentence *****\n",
      "latte vote.\n",
      "\n",
      "ben son di quelle\n",
      "*****************************\n",
      "latte vote.\n",
      "\n",
      "ben son di quelle suo gia` di se' parea si molta,\n",
      "  che l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l'altro stempo si mondo,\n",
      "  che' l'altro che l'altro che l\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 754ms/step - accuracy: 0.5264 - loss: 1.4609 - val_accuracy: 0.4850 - val_loss: 1.6209\n",
      "Epoch 15/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.5333 - loss: 1.4439\n",
      "\n",
      "***** Epoch: 15 *****\n",
      "***** starting sentence *****\n",
      "adre fa sovra figlio deliro,\n",
      "\n",
      "\n",
      "*****************************\n",
      "adre fa sovra figlio deliro,\n",
      "\n",
      "di parlar di sol che l'altro volto\n",
      "  di che l'altro volto di sol che s'accorta\n",
      "  di qual fu come tu che s'accorta,\n",
      "  che l'altro volto di sol che s'accorta\n",
      "  di qual fu come tu che s'accorta,\n",
      "  che l'altro volto di sol che s'accorta\n",
      "  di qual fu come tu che s'accorta,\n",
      "  che l'altro volto di sol che s'accorta\n",
      "  di qual fu come tu che s'accorta,\n",
      "  che l'altro volto di sol che s'accorta\n",
      "  di qual fu \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 767ms/step - accuracy: 0.5333 - loss: 1.4439 - val_accuracy: 0.4858 - val_loss: 1.6194\n",
      "Epoch 16/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.5432 - loss: 1.4111\n",
      "\n",
      "***** Epoch: 16 *****\n",
      "***** starting sentence *****\n",
      "e l'alpe per cadere ad una sce\n",
      "*****************************\n",
      "e l'alpe per cadere ad una scella,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mio disse a la piange tanto il piange,\n",
      "  che 'l mi\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 761ms/step - accuracy: 0.5431 - loss: 1.4113 - val_accuracy: 0.4836 - val_loss: 1.6233\n",
      "Epoch 17/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.5478 - loss: 1.3904\n",
      "\n",
      "***** Epoch: 17 *****\n",
      "***** starting sentence *****\n",
      "obbi\n",
      "  esso litare stato accet\n",
      "*****************************\n",
      "obbi\n",
      "  esso litare stato accetto a la sua corta,\n",
      "  si` che 'l viso di se' piu` di colui che si morte,\n",
      "  che si veder non si fara e diro,\n",
      "  per che 'l viso di se' piu` di colui che si morte,\n",
      "  che si veder non si fara e diro,\n",
      "  per che 'l viso di se' piu` di colui che si morte,\n",
      "  che si veder non si fara e diro,\n",
      "  per che 'l viso di se' piu` di colui che si morte,\n",
      "  che si veder non si fara e diro,\n",
      "  per che 'l viso di se' piu`\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 756ms/step - accuracy: 0.5478 - loss: 1.3906 - val_accuracy: 0.4880 - val_loss: 1.6211\n",
      "Epoch 18/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.5547 - loss: 1.3744\n",
      "\n",
      "***** Epoch: 18 *****\n",
      "***** starting sentence *****\n",
      "rdeva.\n",
      "\n",
      "e cominciai: <<o pomo \n",
      "*****************************\n",
      "rdeva.\n",
      "\n",
      "e cominciai: <<o pomo ch'a vede\n",
      "  che 'l mio di diedi a la vista non piedi,\n",
      "  che 'l mio disse: <<quella che son la` di quel ch'io son l'altro a dio, si` ch'io t'asser la fiata\n",
      "  che 'l mio di diedi a la vista non piedi,\n",
      "  che 'l mio disse: <<quella che son la` di quel ch'io son l'altro a dio, si` ch'io t'asser la fiata\n",
      "  che 'l mio di diedi a la vista non piedi,\n",
      "  che 'l mio disse: <<quella che son la` di quel ch'io s\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 758ms/step - accuracy: 0.5546 - loss: 1.3746 - val_accuracy: 0.4867 - val_loss: 1.6301\n",
      "Epoch 19/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.5634 - loss: 1.3488\n",
      "\n",
      "***** Epoch: 19 *****\n",
      "***** starting sentence *****\n",
      "io;\n",
      "  e 'l gran centauro disse\n",
      "*****************************\n",
      "io;\n",
      "  e 'l gran centauro disse: <<qui la` di quel che si stanta\n",
      "  che si comanti al suo prese e 'l capolio,\n",
      "  che si fa di quel che si stanta\n",
      "  che si comanti al suo prese e 'l capolio,\n",
      "  che si fa di quel che si stanta\n",
      "  che si comanti al suo prese e 'l capolio,\n",
      "  che si fa di quel che si stanta\n",
      "  che si comanti al suo prese e 'l capolio,\n",
      "  che si fa di quel che si stanta\n",
      "  che si comanti al suo prese e 'l capolio,\n",
      "  che si f\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 758ms/step - accuracy: 0.5633 - loss: 1.3490 - val_accuracy: 0.4858 - val_loss: 1.6339\n",
      "Epoch 20/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.5676 - loss: 1.3320\n",
      "\n",
      "***** Epoch: 20 *****\n",
      "***** starting sentence *****\n",
      "resso a l'ultima salute>>,\n",
      "  c\n",
      "*****************************\n",
      "resso a l'ultima salute>>,\n",
      "  comincio` come corte di colui che 'l vero,\n",
      "  che 'l proprio di colui che l'altro e` corto son discerde,\n",
      "  che si conversa la sua con la stala.\n",
      "\n",
      "andava la con sua per la sua mar parte,\n",
      "  che si conversa la sua con la stala.\n",
      "\n",
      "andava la con sua per la sua mar parte,\n",
      "  che si conversa la sua con la stala.\n",
      "\n",
      "andava la con sua per la sua mar parte,\n",
      "  che si conversa la sua con la stala.\n",
      "\n",
      "andava la con sua\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 782ms/step - accuracy: 0.5675 - loss: 1.3323 - val_accuracy: 0.4856 - val_loss: 1.6435\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size = 2048, \n",
    "        epochs = 20, \n",
    "        callbacks = [print_callback], \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Divide the sequence into training, validation and testing in an balanced way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing dei dati andando a dividere i canti\n",
    "\n",
    "cantiche = re.split(r'\\n(inferno|purgatorio|paradiso)\\n', text)\n",
    "\n",
    "cantiche = [canto.strip() for canto in cantiche if canto.strip() and canto.lower() not in ['inferno', 'purgatorio', 'paradiso']]\n",
    "\n",
    "print(cantiche)\n",
    "print(\"Total cantiche: \", len(cantiche))\n",
    "print(cantiche[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERNO\n",
    "canti_inferno = re.split(r'(?<=\\n)(inferno):\\s*canto\\s*[ivxlcdm]+\\n*', cantiche[0])\n",
    "\n",
    "canti_inferno = [canto.strip() for canto in canti_inferno if canto.strip() and canto.lower() not in ['inferno']]\n",
    "\n",
    "# The first element of 'canti', namely 'Inferno', is removed from the list to obtain a list containing only the canti\n",
    "if canti_inferno[0].lower() in ['inferno', 'purgatorio', 'paradiso']:\n",
    "    canti_inferno = canti_inferno[1:]\n",
    "\n",
    "print(\"Number of canti: \", len(canti_inferno))\n",
    "\n",
    "train_size_inferno = int(0.7 * len(canti_inferno))\n",
    "val_size_inferno = int(0.2 * len(canti_inferno))\n",
    "test_size_inferno = len(canti_inferno) - train_size_inferno - val_size_inferno\n",
    "\n",
    "train_inferno = canti_inferno[:train_size_inferno]\n",
    "val_inferno = canti_inferno[train_size_inferno:train_size_inferno + val_size_inferno]\n",
    "test_inferno = canti_inferno[train_size_inferno + val_size_inferno:]\n",
    "\n",
    "print(f\"Training set: {len(train_inferno)} canti\")\n",
    "print(f\"Validation set: {len(val_inferno)} canti\")\n",
    "print(f\"Test set: {len(test_inferno)} canti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURGATORIO\n",
    "canti_purgatorio = re.split(r'(?<=\\n)(purgatorio):\\s*canto\\s*[ivxlcdm]+\\n*', cantiche[1])\n",
    "\n",
    "canti_purgatorio = [canto.strip() for canto in canti_purgatorio if canto.strip() and canto.lower() not in ['purgatorio']]\n",
    "\n",
    "# The first element of 'canti', namely 'Inferno', is removed from the list to obtain a list containing only the canti \n",
    "if canti_purgatorio[0].lower() in ['purgatorio']:\n",
    "    canti_purgatorio = canti_purgatorio[1:]\n",
    "\n",
    "print(\"Number of canti: \", len(canti_purgatorio))\n",
    "\n",
    "train_size_purgatorio = int(0.7 * len(canti_purgatorio))\n",
    "val_size_purgatorio = int(0.2 * len(canti_purgatorio))\n",
    "test_size_purgatorio = len(canti_purgatorio) - train_size_purgatorio - val_size_purgatorio\n",
    "\n",
    "train_purgatorio = canti_purgatorio[:train_size_purgatorio]\n",
    "val_purgatorio = canti_purgatorio[train_size_purgatorio:train_size_purgatorio + val_size_purgatorio]\n",
    "test_purgatorio = canti_purgatorio[train_size_purgatorio + val_size_purgatorio:]\n",
    "\n",
    "print(f\"Training set: {len(train_purgatorio)} canti\")\n",
    "print(f\"Validation set: {len(val_purgatorio)} canti\")\n",
    "print(f\"Test set: {len(test_purgatorio)} canti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARADISO\n",
    "canti_paradiso = re.split(r'(?<=\\n)(paradiso):\\s*canto\\s*[ivxlcdm]+\\n*', cantiche[2])\n",
    "\n",
    "canti_paradiso = [canto.strip() for canto in canti_paradiso if canto.strip() and canto.lower() not in ['paradiso']]\n",
    "\n",
    "# The first element of 'canti', namely 'Inferno', is removed from the list to obtain a list containing only the canti. \n",
    "if canti_paradiso[0].lower() in ['paradiso']:\n",
    "    canti_paradiso = canti_paradiso[1:]\n",
    "\n",
    "print(\"Number of canti: \", len(canti_paradiso))\n",
    "\n",
    "train_size_paradiso = int(0.7 * len(canti_paradiso))\n",
    "val_size_paradiso = int(0.2 * len(canti_paradiso))\n",
    "test_size_paradiso = len(canti_paradiso) - train_size_paradiso - val_size_paradiso\n",
    "\n",
    "train_paradiso = canti_paradiso[:train_size_paradiso]\n",
    "val_paradiso = canti_paradiso[train_size_paradiso:train_size_paradiso + val_size_paradiso]\n",
    "test_paradiso = canti_paradiso[train_size_paradiso + val_size_paradiso:]\n",
    "\n",
    "print(f\"Training set: {len(train_paradiso)} canti\")\n",
    "print(f\"Validation set: {len(val_paradiso)} canti\")\n",
    "print(f\"Test set: {len(test_paradiso)} canti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniamo i canti suddivisi per ciascuna cantica nei rispettivi set finali\n",
    "train_canti = train_inferno + train_purgatorio + train_paradiso\n",
    "val_canti = val_inferno + val_purgatorio + val_paradiso\n",
    "test_canti = test_inferno + test_purgatorio + test_paradiso\n",
    "\n",
    "# Stampa la lunghezza dei set\n",
    "print(f\"Training set: {len(train_canti)} canti\")\n",
    "print(f\"Validation set: {len(val_canti)} canti\")\n",
    "print(f\"Test set: {len(test_canti)} canti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_training = ''.join(train_canti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 30 # chunk length\n",
    "step = 3\n",
    "\n",
    "sentences_train, next_chars_train = generete_sequences(''.join(train_canti), maxlen, step)\n",
    "sentences_val, next_chars_val = generete_sequences(''.join(val_canti), maxlen, step)\n",
    "sentences_test, next_chars_test = generete_sequences(''.join(test_canti), maxlen, step)\n",
    "\n",
    "print('number of sequences: ', len(sentences_train))\n",
    "print(sentences_train[11])\n",
    "print(next_chars_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_sequences(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "x_val, y_val = encode_sequences(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "x_test, y_test = encode_sequences(sentences_test, next_chars_test, maxlen, chars, char_indices)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = Sequential()\n",
    "model_b.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model_b.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model_b.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: testAfterEpoch(\n",
    "        epoch,\n",
    "        logs,\n",
    "        maxlen,\n",
    "        text_for_training,\n",
    "        model_b\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = model_b.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size = 2048, \n",
    "        epochs = 20, \n",
    "        callbacks = [print_callback], \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_b.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the chunk length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - maxlen 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50 # chunk length\n",
    "step = 3\n",
    "\n",
    "sentences_train, next_chars_train = generete_sequences(''.join(train_canti), maxlen, step)\n",
    "sentences_val, next_chars_val = generete_sequences(''.join(val_canti), maxlen, step)\n",
    "sentences_test, next_chars_test = generete_sequences(''.join(test_canti), maxlen, step)\n",
    "\n",
    "print('number of sequences: ', len(sentences_train))\n",
    "print(sentences_train[11])\n",
    "print(next_chars_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_sequences(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "x_val, y_val = encode_sequences(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "x_test, y_test = encode_sequences(sentences_test, next_chars_test, maxlen, chars, char_indices)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model3.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model3.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: testAfterEpoch(\n",
    "        epoch,\n",
    "        logs,\n",
    "        maxlen,\n",
    "        text_for_training,\n",
    "        model3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size = 2048, \n",
    "        epochs = 20, \n",
    "        callbacks = [print_callback], \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxlen 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20 # chunk length\n",
    "step = 2\n",
    "\n",
    "sentences_train, next_chars_train = generete_sequences(''.join(train_canti), maxlen, step)\n",
    "sentences_val, next_chars_val = generete_sequences(''.join(val_canti), maxlen, step)\n",
    "sentences_test, next_chars_test = generete_sequences(''.join(test_canti), maxlen, step)\n",
    "\n",
    "print('number of sequences: ', len(sentences_train))\n",
    "print(sentences_train[11])\n",
    "print(next_chars_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_sequences(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "x_val, y_val = encode_sequences(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "x_test, y_test = encode_sequences(sentences_test, next_chars_test, maxlen, chars, char_indices)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model4.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model4.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: testAfterEpoch(\n",
    "        epoch,\n",
    "        logs,\n",
    "        maxlen,\n",
    "        text_for_training,\n",
    "        model4\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size = 2048, \n",
    "        epochs = 20, \n",
    "        callbacks = [print_callback], \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxlen 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 80 # chunk length\n",
    "step = 3\n",
    "\n",
    "sentences_train, next_chars_train = generete_sequences(''.join(train_canti), maxlen, step)\n",
    "sentences_val, next_chars_val = generete_sequences(''.join(val_canti), maxlen, step)\n",
    "sentences_test, next_chars_test = generete_sequences(''.join(test_canti), maxlen, step)\n",
    "\n",
    "print('number of sequences: ', len(sentences_train))\n",
    "print(sentences_train[11])\n",
    "print(next_chars_train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_sequences(sentences_train, next_chars_train, maxlen, chars, char_indices)\n",
    "x_val, y_val = encode_sequences(sentences_val, next_chars_val, maxlen, chars, char_indices)\n",
    "x_test, y_test = encode_sequences(sentences_test, next_chars_test, maxlen, chars, char_indices)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model5.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model5.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: testAfterEpoch(\n",
    "        epoch,\n",
    "        logs,\n",
    "        maxlen,\n",
    "        text_for_training,\n",
    "        model5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = model5.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size = 2048, \n",
    "        epochs = 20, \n",
    "        callbacks = [print_callback], \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
