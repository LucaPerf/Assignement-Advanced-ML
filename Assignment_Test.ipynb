{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Default Payments with Fully-Connected NNs\n",
    "\n",
    "The dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "This dataset employs a binary variable to indicate whether a credit card payment occurred (1 = Yes, 0 = No). The study selected the following 23 factors as explanatory variables:\n",
    "\n",
    "- Variable 1: Amount of credit granted (in local currency), which includes both individual credit and family (supplementary) credit.\n",
    "- Variable 2: Gender (1 = male; 2 = female).\n",
    "- Variable 3: Education level (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "- Variable 4: Age (years).\n",
    "- Variables 5-10: Payment history over several months. The scale for payment status ranges from -1 (paid on time) to 9 (delayed by nine months or more). It tracks payments from April to September:\n",
    "\n",
    "    - Variable 5: Payment status in September;\n",
    "    - Variable 6: Payment status in August;\n",
    "    - Variable 7: Payment status in July;\n",
    "    - Variable 8: Payment status in June;\n",
    "    - Variable 9: Payment status in May;\n",
    "    - Variable 10: Payment status in April. \n",
    "- Variables 11-16: Amount of monthly billing (in local currency), tracking statements from September to April.\n",
    "- Variables 17-22: Amount of previous payments (in local currency), corresponding to monthly payments made from September to April."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the data\n",
    "\n",
    "any comment about data dimensionality/distribution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librerie\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carichiamo il dataset\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlla la dimensionalità del dataset di training e test\n",
    "print(\"Dimensionalità del dataset di training:\", train_data.shape)\n",
    "print(\"Dimensionalità del dataset di test:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controllo presenza di valori nulli\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controllo di presenza di valori duplicati\n",
    "train_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isinf(train_data.values).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi statica univariata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra i valori unici di ciascuna colonna categorica\n",
    "categorical_columns = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {train_data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabili numeriche e categoriche\n",
    "numerical_columns = ['LIMIT_BAL', 'AGE'] + [f'BILL_AMT{i}' for i in range(1, 7)] + [f'PAY_AMT{i}' for i in range(1, 7)]\n",
    "categorical_columns = ['SEX', 'EDUCATION', 'MARRIAGE'] + ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Analisi univariata delle variabili numeriche\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(train_data[column], kde=True, color='skyblue')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Analisi univariata con percentuali per variabili categoriche\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=train_data[column], color='lightgreen')\n",
    "    plt.title(f'Count of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'default payment next month'\n",
    "total_rows = len(train_data)\n",
    "counts = train_data[column].value_counts()\n",
    "percentages = [count / total_rows * 100 for count in counts]\n",
    "plt.pie(percentages, autopct='%1.1f%%', colors=['green', 'orange'])\n",
    "plt.title(f'Proportion of {column} (target)')\n",
    "labels = ['0', '1']\n",
    "plt.legend(labels=labels, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponendo che il target sia la colonna 'default payment next month' del DataFrame df\n",
    "class_counts = train_data['default payment next month'].value_counts()\n",
    "\n",
    "# Mostra la distribuzione delle classi\n",
    "print(\"Distribuzione delle classi:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Grafico a torta\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=90, colors=['#66c2a5', '#fc8d62'])\n",
    "plt.title('Distribuzione delle Classi')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi Statica Multivariata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature categoriche\n",
    "categorical_columns = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Relazione tra variabili categoriche e la variabile target\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=column, hue='default payment next month', data=train_data, palette='coolwarm')\n",
    "    plt.title(f'{column} distribution by Default Payment Status')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(title='Default Payment')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la correlazione tra ogni feature e il target\n",
    "correlation = train_data.drop('default payment next month', axis=1).corrwith(train_data['default payment next month'])\n",
    "\n",
    "# Crea un grafico a barre per visualizzare le correlazioni\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation.plot(kind='bar', grid=True, color='orange')\n",
    "plt.title(\"Correlazione con 'default payment next month'\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Correlazione\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relazioni tra variabili\n",
    "# Mappa di correlazione\n",
    "plt.figure(figsize=(16, 13))\n",
    "correlation_matrix = train_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matrice di correlazione delle variabili numeriche')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data.drop(columns=['ID'])\n",
    "#df = df.drop(columns=['LIMIT_BAL'])\n",
    "#df = df.drop(columns=['SEX'])\n",
    "#df = df.drop(columns=['MARRIAGE'])\n",
    "#df = df.drop(columns=['BILL_AMT1'])\n",
    "#df = df.drop(columns=['BILL_AMT2'])\n",
    "#df = df.drop(columns=['BILL_AMT3'])\n",
    "#df = df.drop(columns=['BILL_AMT4'])\n",
    "#df = df.drop(columns=['BILL_AMT5'])\n",
    "#df = df.drop(columns=['BILL_AMT6'])\n",
    "#df = df.drop(columns=['PAY_AMT1'])\n",
    "#df = df.drop(columns=['PAY_AMT2'])\n",
    "#df = df.drop(columns=['PAY_AMT3'])\n",
    "#df = df.drop(columns=['PAY_AMT4'])\n",
    "#df = df.drop(columns=['PAY_AMT5'])\n",
    "#df = df.drop(columns=['PAY_AMT6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "describe the choice made during the preprocessing operations, also taking into account the previous considerations during the data inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "any description/comment about the procedure you followed in the choice of the network structure and hyperparameters goes here, together with consideration about the training/optimization procedure (e.g. optimizer choice, final activations, loss functions, training metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX'] = df['SEX'].astype('category')\n",
    "df['EDUCATION'] = df['EDUCATION'].astype('category')\n",
    "df['MARRIAGE'] = df['MARRIAGE'].astype('category')\n",
    "df['PAY_0'] = df['PAY_0'].astype('category')\n",
    "df['PAY_2'] = df['PAY_2'].astype('category')\n",
    "df['PAY_3'] = df['PAY_3'].astype('category')\n",
    "df['PAY_4'] = df['PAY_4'].astype('category')\n",
    "df['PAY_5'] = df['PAY_5'].astype('category')\n",
    "df['PAY_6'] = df['PAY_6'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['default payment next month']\n",
    "X = df.drop(columns=['default payment next month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizzare \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iperparametri da vedere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network \n",
    "dims = x_train.shape[1]\n",
    "print('Input Shape =', dims)\n",
    "\n",
    "#y_train = to_categorical(y_train)\n",
    "\n",
    "nb_classes = 1\n",
    "print('Number classes = Output Shape =', nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input((dims,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "history = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "  x_plot = list(range(1,len(history.history[\"loss\"])+1))\n",
    "  plt.figure()\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.plot(x_plot, history.history['loss'])\n",
    "  plt.plot(x_plot, history.history['val_loss'])\n",
    "  plt.legend(['Training', 'Validation'])\n",
    "\n",
    "def plot_accuracy(history):\n",
    "  x_plot = list(range(1,len(history.history[\"accuracy\"])+1))\n",
    "  plt.figure()\n",
    "  plt.title(\"Accuracy\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.plot(x_plot, history.history['accuracy'])\n",
    "  plt.plot(x_plot, history.history['val_accuracy'])\n",
    "  plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Ottenere le previsioni per il set di test\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "# Arrotondare le previsioni per ottenere una previsione binaria\n",
    "y_pred_test_bin = np.round(y_pred_test)\n",
    "\n",
    "# Ottenere le previsioni per il set di train\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "# Arrotondare le previsioni per ottenere una previsione binaria\n",
    "y_pred_train_bin = np.round(y_pred_train)\n",
    "\n",
    "print(\"Prestazioni sul Set di Addestramento:\")\n",
    "print(classification_report(y_train, y_pred_train_bin))\n",
    "\n",
    "print(\"Prestazioni sul Set di Test:\")\n",
    "print(classification_report(y_test, y_pred_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Calcolo della matrice di confusione\n",
    "cm = confusion_matrix(y_pred_test_bin, y_test)\n",
    "labels = [1,0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and comment the training results\n",
    "\n",
    "here goes any comment/visualization of the training history and any initial consideration on the training results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model and comment the results\n",
    "\n",
    "please describe the evaluation procedure on a validation set, commenting the generalization capability of your model (e.g. under/overfitting). You may also describe the performance metrics that you choose: what is the most suitable performance measure (or set of performance measures) in this case/dataset, according to you? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions (on the provided test set)\n",
    "\n",
    "Based on the results obtained and analyzed during the training and the validation phases, what are your (rather _personal_) expectations with respect to the performances of your model on the blind external test set? Briefly motivate your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL -- Export the predictions in the format indicated in the assignment release page and verify you prediction on the [assessment page](https://aml-assignmentone-2425.streamlit.app/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
